{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Power Generation Data Exploration\n",
    "\n",
    "This notebook explores the solar farm data to understand the structure, quality, and relationships in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = '/home/ubuntu/upload/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data File Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data files\n",
    "all_files = glob.glob(os.path.join(DATA_DIR, '*.csv'))\n",
    "all_files.extend(glob.glob(os.path.join(DATA_DIR, '*.xlsx')))\n",
    "all_files.extend(glob.glob(os.path.join(DATA_DIR, '*.ttl')))\n",
    "\n",
    "print(f\"Total files: {len(all_files)}\")\n",
    "\n",
    "# Categorize files\n",
    "power_generation_files = [f for f in all_files if not any(weather in f for weather in \n",
    "                         ['Temperature', 'Humidity', 'Irradiance', 'Wind', 'Visibility', \n",
    "                          'SeaLevelPressure', 'RelativeHumidity', 'Rainfall']) \n",
    "                         and not 'Inverter' in f and f.endswith('.csv')]\n",
    "\n",
    "inverter_files = [f for f in all_files if 'Inverter' in f]\n",
    "\n",
    "weather_files = [f for f in all_files if any(weather in f for weather in \n",
    "                ['Temperature', 'Humidity', 'Irradiance', 'Wind', 'Visibility', \n",
    "                 'SeaLevelPressure', 'RelativeHumidity', 'Rainfall'])]\n",
    "\n",
    "metadata_files = [f for f in all_files if f.endswith('.ttl')]\n",
    "\n",
    "print(f\"\\nPower generation files: {len(power_generation_files)}\")\n",
    "print(f\"Inverter files: {len(inverter_files)}\")\n",
    "print(f\"Weather files: {len(weather_files)}\")\n",
    "print(f\"Metadata files: {len(metadata_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Power Generation Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a few power generation files to understand structure\n",
    "sample_power_files = power_generation_files[:5]\n",
    "\n",
    "for file in sample_power_files:\n",
    "    print(f\"\\n=== {os.path.basename(file)} ===\")\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Date range: {df['Time'].iloc[0]} to {df['Time'].iloc[-1]}\")\n",
    "    print(f\"Sample data:\")\n",
    "    print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine all power generation data\n",
    "def load_power_data(file_path):\n",
    "    \"\"\"Load power generation data with proper datetime parsing\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    df['station'] = os.path.basename(file_path).replace('.csv', '')\n",
    "    return df\n",
    "\n",
    "# Load first few files for analysis\n",
    "power_data_list = []\n",
    "for file in power_generation_files[:10]:  # Start with first 10 files\n",
    "    try:\n",
    "        df = load_power_data(file)\n",
    "        power_data_list.append(df)\n",
    "        print(f\"Loaded {os.path.basename(file)}: {df.shape[0]} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "# Combine data\n",
    "if power_data_list:\n",
    "    combined_power_data = pd.concat(power_data_list, ignore_index=True)\n",
    "    print(f\"\\nCombined power data shape: {combined_power_data.shape}\")\n",
    "    print(f\"Date range: {combined_power_data['Time'].min()} to {combined_power_data['Time'].max()}\")\n",
    "    print(f\"Unique stations: {combined_power_data['station'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weather Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze weather data structure\n",
    "weather_data_dict = {}\n",
    "\n",
    "for file in weather_files:\n",
    "    weather_type = os.path.basename(file).split('_')[0]\n",
    "    year = os.path.basename(file).split('_')[1].replace('.csv', '').replace('.xlsx', '')\n",
    "    \n",
    "    try:\n",
    "        if file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file)\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "        \n",
    "        df['Time'] = pd.to_datetime(df['Time'])\n",
    "        \n",
    "        key = f\"{weather_type}_{year}\"\n",
    "        weather_data_dict[key] = df\n",
    "        \n",
    "        print(f\"{key}: {df.shape[0]} records, columns: {list(df.columns)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(weather_data_dict)} weather datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine weather data by type\n",
    "weather_types = ['Temperature', 'Irradiance', 'RelativeHumidity', 'Wind', 'Rainfall', 'SeaLevelPressure', 'Visibility']\n",
    "combined_weather = {}\n",
    "\n",
    "for weather_type in weather_types:\n",
    "    type_data = []\n",
    "    for key, df in weather_data_dict.items():\n",
    "        if weather_type in key:\n",
    "            type_data.append(df)\n",
    "    \n",
    "    if type_data:\n",
    "        combined_df = pd.concat(type_data, ignore_index=True)\n",
    "        combined_df = combined_df.sort_values('Time').reset_index(drop=True)\n",
    "        combined_weather[weather_type] = combined_df\n",
    "        print(f\"{weather_type}: {combined_df.shape[0]} records from {combined_df['Time'].min()} to {combined_df['Time'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in power data\n",
    "if 'combined_power_data' in locals():\n",
    "    print(\"=== Power Data Quality ===\")\n",
    "    print(f\"Missing values:\")\n",
    "    print(combined_power_data.isnull().sum())\n",
    "    \n",
    "    print(f\"\\nData types:\")\n",
    "    print(combined_power_data.dtypes)\n",
    "    \n",
    "    print(f\"\\nBasic statistics:\")\n",
    "    print(combined_power_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check weather data quality\n",
    "print(\"=== Weather Data Quality ===\")\n",
    "for weather_type, df in combined_weather.items():\n",
    "    print(f\"\\n{weather_type}:\")\n",
    "    print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
    "    print(f\"  Date range: {df['Time'].min()} to {df['Time'].max()}\")\n",
    "    print(f\"  Records: {len(df)}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['Time']).sum()\n",
    "    print(f\"  Duplicate timestamps: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot power generation patterns\n",
    "if 'combined_power_data' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Sample one station for detailed analysis\n",
    "    sample_station = combined_power_data['station'].iloc[0]\n",
    "    station_data = combined_power_data[combined_power_data['station'] == sample_station].copy()\n",
    "    \n",
    "    # Daily pattern\n",
    "    station_data['hour'] = station_data['Time'].dt.hour\n",
    "    hourly_avg = station_data.groupby('hour')['power(W)'].mean()\n",
    "    axes[0,0].plot(hourly_avg.index, hourly_avg.values)\n",
    "    axes[0,0].set_title(f'Average Hourly Power Generation - {sample_station}')\n",
    "    axes[0,0].set_xlabel('Hour of Day')\n",
    "    axes[0,0].set_ylabel('Power (W)')\n",
    "    \n",
    "    # Time series\n",
    "    sample_week = station_data.head(672)  # One week of 15-min data\n",
    "    axes[0,1].plot(sample_week['Time'], sample_week['power(W)'])\n",
    "    axes[0,1].set_title('Power Generation Time Series (Sample Week)')\n",
    "    axes[0,1].set_xlabel('Time')\n",
    "    axes[0,1].set_ylabel('Power (W)')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Power distribution\n",
    "    axes[1,0].hist(station_data['power(W)'], bins=50, alpha=0.7)\n",
    "    axes[1,0].set_title('Power Generation Distribution')\n",
    "    axes[1,0].set_xlabel('Power (W)')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Monthly pattern\n",
    "    station_data['month'] = station_data['Time'].dt.month\n",
    "    monthly_avg = station_data.groupby('month')['power(W)'].mean()\n",
    "    axes[1,1].bar(monthly_avg.index, monthly_avg.values)\n",
    "    axes[1,1].set_title('Average Monthly Power Generation')\n",
    "    axes[1,1].set_xlabel('Month')\n",
    "    axes[1,1].set_ylabel('Power (W)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/ubuntu/power_generation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weather patterns\n",
    "if combined_weather:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (weather_type, df) in enumerate(combined_weather.items()):\n",
    "        if i >= 6:  # Only plot first 6 weather types\n",
    "            break\n",
    "            \n",
    "        # Sample data for plotting (every 60th point to reduce density)\n",
    "        sample_df = df.iloc[::60].copy()\n",
    "        \n",
    "        column_name = [col for col in df.columns if col != 'Time'][0]\n",
    "        \n",
    "        axes[i].plot(sample_df['Time'], sample_df[column_name], alpha=0.7)\n",
    "        axes[i].set_title(f'{weather_type} Over Time')\n",
    "        axes[i].set_xlabel('Time')\n",
    "        axes[i].set_ylabel(column_name)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/ubuntu/weather_patterns.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a merged dataset for correlation analysis\n",
    "if 'combined_power_data' in locals() and combined_weather:\n",
    "    # Sample one station\n",
    "    sample_station_data = combined_power_data[combined_power_data['station'] == sample_station].copy()\n",
    "    \n",
    "    # Resample weather data to 15-minute intervals to match power data\n",
    "    merged_data = sample_station_data[['Time', 'power(W)']].copy()\n",
    "    \n",
    "    for weather_type, weather_df in combined_weather.items():\n",
    "        # Resample to 15-minute intervals\n",
    "        weather_df_resampled = weather_df.set_index('Time').resample('15T').mean().reset_index()\n",
    "        \n",
    "        # Merge with power data\n",
    "        column_name = [col for col in weather_df.columns if col != 'Time'][0]\n",
    "        weather_df_resampled = weather_df_resampled[['Time', column_name]]\n",
    "        weather_df_resampled.columns = ['Time', weather_type]\n",
    "        \n",
    "        merged_data = pd.merge(merged_data, weather_df_resampled, on='Time', how='left')\n",
    "    \n",
    "    print(f\"Merged dataset shape: {merged_data.shape}\")\n",
    "    print(f\"Missing values in merged data:\")\n",
    "    print(merged_data.isnull().sum())\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlation_matrix = merged_data.select_dtypes(include=[np.number]).corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Correlation Matrix: Power Generation vs Weather Variables')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/home/ubuntu/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print correlations with power generation\n",
    "    power_correlations = correlation_matrix['power(W)'].sort_values(ascending=False)\n",
    "    print(\"\\nCorrelations with Power Generation:\")\n",
    "    print(power_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATA EXPLORATION SUMMARY ===\")\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Power generation files: {len(power_generation_files)}\")\n",
    "print(f\"   - Weather data types: {len(combined_weather)}\")\n",
    "print(f\"   - Time range: 2021-2023\")\n",
    "print(f\"   - Power data frequency: 15 minutes\")\n",
    "print(f\"   - Weather data frequency: 1 minute\")\n",
    "\n",
    "if 'combined_power_data' in locals():\n",
    "    print(f\"\\n2. Power Generation Data:\")\n",
    "    print(f\"   - Total records: {len(combined_power_data):,}\")\n",
    "    print(f\"   - Unique stations: {combined_power_data['station'].nunique()}\")\n",
    "    print(f\"   - Average power: {combined_power_data['power(W)'].mean():.2f} W\")\n",
    "    print(f\"   - Max power: {combined_power_data['power(W)'].max():.2f} W\")\n",
    "\n",
    "if combined_weather:\n",
    "    print(f\"\\n3. Weather Data:\")\n",
    "    for weather_type, df in combined_weather.items():\n",
    "        column_name = [col for col in df.columns if col != 'Time'][0]\n",
    "        print(f\"   - {weather_type}: {len(df):,} records, avg: {df[column_name].mean():.2f}\")\n",
    "\n",
    "if 'correlation_matrix' in locals():\n",
    "    print(f\"\\n4. Key Correlations with Power Generation:\")\n",
    "    top_correlations = power_correlations.drop('power(W)').head(3)\n",
    "    for var, corr in top_correlations.items():\n",
    "        print(f\"   - {var}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\n5. Data Quality Issues:\")\n",
    "print(f\"   - Weather data needs resampling to match power data frequency\")\n",
    "print(f\"   - Some missing values in weather data\")\n",
    "print(f\"   - Need to handle timezone and daylight patterns\")\n",
    "print(f\"   - Multiple stations need aggregation strategy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

